{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KANG-HYUNIL/AudioTrain/blob/main/AudioTrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c94588f7"
      },
      "source": [
        "# Notebook Explanation\n",
        "\n",
        "This notebook demonstrates a process for audio classification, including data loading, preprocessing, data augmentation, building and training deep learning models (CNN and CRNN), and evaluating their performance using K-Fold cross-validation.\n",
        "\n",
        "## Setup and Environment\n",
        "\n",
        "This section installs necessary packages, sets up the environment, and connects to Google Drive to access data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9cca8cd"
      },
      "source": [
        "#우선 colab에서 실험 및 실습할 때에 필요한 패키지들을 설치해보자\n",
        "!pip -q install librosa torchaudio soundfile ipywidgets numpy pandas tqdm tensorflow tensorflow-datasets scikit-learn mirdata\n",
        "!apt-get update\n",
        "!apt-get install -y sox libsox-dev libsox-fmt-all\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import soundfile as sf\n",
        "import torchaudio\n",
        "\n",
        "import os, glob, numpy as np, pandas as pd\n",
        "import librosa, soundfile as sf\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import random\n",
        "from torchaudio import sox_effects\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "import tensorflow.keras\n",
        "\n",
        "\n",
        "# Google Drive 연결 및 Kaggle 용 폴더 만들기\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d662ec9"
      },
      "source": [
        "This cell verifies GPU availability and configures TensorFlow to use memory growth, which helps in managing GPU memory more efficiently during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae67d923"
      },
      "source": [
        "# GPU 확인\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1) GPU 장치 확인 + 메모리 성장\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"GPUs:\", gpus)\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)  # 점진 할당"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f18aeb37"
      },
      "source": [
        "This cell demonstrates loading and visualizing a sample audio file using the `librosa` library. It shows how to load a `.wav` file, resample it, display its waveform, and play the audio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9473d92"
      },
      "source": [
        "# 실제로 wav 파일 load해보기\n",
        "\n",
        "\n",
        "# # wav 들어있는 경로들 중 하나\n",
        "# preprocessed_data = Path(\"/content/drive/MyDrive/kaggle_cache/tf_speech_cmds/preprocessed_data\")\n",
        "\n",
        "# 전처리해서 npy로 변환한 데이터만 google drive에 있기에, librosa 예제로 해보자, 샘플 파일이 있다고 하네\n",
        "wav_path = librosa.ex('trumpet')\n",
        "\n",
        "#librosa.load로 wav를 load하는 과정\n",
        "#sr은 샘플레이트 Hz 설정. 이전에 샘플레이트 개념 간단하게라도 보앗엇지?\n",
        "# 1초에 얼마나 많은 데이터를 담아둘 지 정하는 수치. sr를 load메서드에 인자로 넣으면, path에 있는 데이터를 알아서 sr수치로 리샘플링 한다고\n",
        "# 근데 그러면 데이터의 길이가 줄어드는건가? 흠\n",
        "y, sr = librosa.load(wav_path, sr=22050, mono=True)\n",
        "print(f\"Librosa Loaded: y.shape={y.shape}, sr={sr}\")\n",
        "\n",
        "# 받아온 파형을 한 번 시각화해보자\n",
        "plt.figure(figsize = (10, 3))\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#ipd를 통해 실제 듣기도 가능하다고\n",
        "ipd.Audio(y, rate=sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51620449"
      },
      "source": [
        "This section defines functions and parameters for data augmentation techniques applied to audio files. It includes settings for output directories, augmentation probabilities, and parameter ranges for effects like gain, noise, time stretch, pitch shift, EQ, and reverb. Utility functions for loading and normalizing audio are also included."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d879c255"
      },
      "source": [
        "# Data Augmentation 진행해보자\n",
        "\n",
        "# Wav, 즉 음원 파일 자체에 좀 변경을 가하는 것들로만 우선./\n",
        "import random\n",
        "\n",
        "# =========================================\n",
        "# [셀 2] 경로 & 하이퍼파라미터 설정\n",
        "# =========================================\n",
        "DATA_RAW_DIR = \"/content/drive/MyDrive/audioPractice/raw\"      # 입력: class별 폴더에 .wav\n",
        "DATA_AUG_DIR = \"/content/drive/MyDrive/audioPractice/aug\"      # 출력: 증강된 wav 저장\n",
        "META_DIR      = \"/content/drive/MyDrive/audioPractice/meta\"     # 출력: train/val CSV\n",
        "\n",
        "\n",
        "\n",
        "# 미리 경로 생성\n",
        "os.makedirs(DATA_AUG_DIR, exist_ok=True)\n",
        "os.makedirs(META_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# 증강 개수: 각 원본 파일당 생성할 증강본 수\n",
        "AUG_PER_FILE = 2\n",
        "\n",
        "# 학습/검증 분할 비율\n",
        "VAL_RATIO = 0.2\n",
        "\n",
        "# 공통 샘플레이트(통일 권장). None이면 원본 SR 유지\n",
        "TARGET_SR = 22050\n",
        "\n",
        "\n",
        "# 랜덤 증강 확률 (필요에 맞게 조정)\n",
        "P_GAIN      = 0.7\n",
        "P_NOISE     = 0.7\n",
        "P_STRETCH   = 0.5\n",
        "P_PITCH     = 0.5\n",
        "P_EQ        = 0.5\n",
        "P_REVERB    = 0.5\n",
        "\n",
        "\n",
        "# 파라미터 범위\n",
        "GAIN_DB_RANGE       = (-6, 6)            # dB\n",
        "NOISE_SNR_DB_CHOICES = [30, 20, 10]      # dB\n",
        "STRETCH_RATE_RANGE  = (0.9, 1.1)         # <1 느리게, >1 빠르게\n",
        "PITCH_STEPS_CHOICES = [-2, -1, 1, 2]     # 반음\n",
        "\n",
        "\n",
        "# SoX EQ: [\"equalizer\", center_freq(Hz), Q, gain(dB)]\n",
        "EQ_PRESETS = [\n",
        "    [\"equalizer\", \"120\", \"1.0q\", \"-6\"],\n",
        "    [\"equalizer\", \"1000\", \"1.0q\", \"+3\"],\n",
        "    [\"equalizer\", \"4000\", \"1.0q\", \"+2\"],\n",
        "]\n",
        "# SoX Reverb: [\"reverb\", reverberance, HF_damping, room_scale]\n",
        "REVERB_PRESETS = [\n",
        "    [\"reverb\", \"30\", \"30\", \"50\"],\n",
        "    [\"reverb\", \"50\", \"50\", \"70\"],\n",
        "    [\"reverb\", \"70\", \"50\", \"90\"],\n",
        "]\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# [셀 3] 유틸 함수 (오디오 I/O, 정규화 등)\n",
        "# =========================================\n",
        "def load_mono(path, target_sr=TARGET_SR):\n",
        "    y, sr = librosa.load(path, sr=target_sr, mono=True)\n",
        "    return y.astype(np.float32), sr\n",
        "\n",
        "def peak_normalize(y, eps=1e-9):\n",
        "    peak = np.max(np.abs(y))\n",
        "    if peak < eps:\n",
        "        return y\n",
        "    return (y / (peak + eps)).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# [셀 4] 증강 함수 (WAV 레벨)\n",
        "# =========================================\n",
        "def aug_gain(y):\n",
        "    db = np.random.uniform(*GAIN_DB_RANGE)\n",
        "    g  = 10**(db/20.0)\n",
        "    return np.clip(y * g, -1.0, 1.0)\n",
        "\n",
        "def aug_noise(y, snr_db=None):\n",
        "    if snr_db is None:\n",
        "        snr_db = random.choice(NOISE_SNR_DB_CHOICES)\n",
        "    sig_pwr = np.mean(y**2) + 1e-12\n",
        "    noise_pwr = sig_pwr / (10**(snr_db/10))\n",
        "    noise = np.random.normal(0.0, np.sqrt(noise_pwr), size=y.shape).astype(np.float32)\n",
        "    return np.clip(y + noise, -1.0, 1.0)\n",
        "\n",
        "def aug_time_stretch(y, sr):\n",
        "    rate = np.random.uniform(*STRETCH_RATE_RANGE)\n",
        "    # librosa time-stretch는 길이가 변함 (라벨 동기화 필요할 수 있음)\n",
        "    y2 = librosa.effects.time_stretch(y, rate=rate).astype(np.float32)\n",
        "    return y2\n",
        "\n",
        "def aug_pitch_shift(y, sr):\n",
        "    steps = random.choice(PITCH_STEPS_CHOICES)\n",
        "    y2 = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps).astype(np.float32)\n",
        "    return y2\n",
        "\n",
        "def to_torch_wave(y):\n",
        "    # torchaudio sox_effects는 [C, T] 텐서 필요\n",
        "    return torchaudio.functional.resample(\n",
        "        torch.tensor(y).unsqueeze(0), orig_freq=sr, new_freq=sr\n",
        "    )\n",
        "\n",
        "\n",
        "def run_sox_effects_numpy(y, sr, effects_chain):\n",
        "    \"\"\"\n",
        "    torchaudio sox_effects를 numpy(y) 입력에 적용하고 numpy로 반환\n",
        "    \"\"\"\n",
        "    wav_t = torch.from_numpy(y).unsqueeze(0)  # [1, T]\n",
        "    out, out_sr = sox_effects.apply_effects_tensor(wav_t, sr, effects_chain)\n",
        "    out = out.squeeze(0).numpy().astype(np.float32)\n",
        "    return out, out_sr\n",
        "\n",
        "# 수정 제안: EQ 효과 뒤에 채널 효과 추가\n",
        "def aug_eq(y, sr):\n",
        "    # EQ 프리셋 중 랜덤 1~2개 적용\n",
        "    n = random.choice([1, 2])\n",
        "    eq_chain = random.sample(EQ_PRESETS, n)\n",
        "\n",
        "    # 채널을 1로 강제하는 효과 추가\n",
        "    # EQ 효과 뒤에 추가합니다.\n",
        "    final_chain = eq_chain + [[\"channels\", \"1\"]]\n",
        "\n",
        "    out, _ = run_sox_effects_numpy(y, sr, final_chain)\n",
        "    return out\n",
        "\n",
        "def aug_reverb(y, sr):\n",
        "    chain = [random.choice(REVERB_PRESETS)]\n",
        "    # 채널을 1로 강제하는 효과 추가\n",
        "    chain.append([\"channels\", \"1\"])\n",
        "    out, _ = run_sox_effects_numpy(y, sr, chain)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# [셀 5] 랜덤 증강 파이프라인\n",
        "# =========================================\n",
        "def random_augment(y, sr):\n",
        "    \"\"\"\n",
        "    - 확률적으로 여러 증강을 '연속 적용' (순서 중요 X, 간단 버전)\n",
        "    - 마지막에 peak normalize로 출력 안전하게\n",
        "    \"\"\"\n",
        "    out = y.copy()\n",
        "\n",
        "    if random.random() < P_GAIN:\n",
        "        out = aug_gain(out)\n",
        "\n",
        "    if random.random() < P_NOISE:\n",
        "        out = aug_noise(out)\n",
        "\n",
        "    # if random.random() < P_STRETCH:\n",
        "    #     out = aug_time_stretch(out, sr)\n",
        "\n",
        "    if random.random() < P_PITCH:\n",
        "        out = aug_pitch_shift(out, sr)\n",
        "\n",
        "    if random.random() < P_EQ:\n",
        "        out = aug_eq(out, sr)\n",
        "\n",
        "    if random.random() < P_REVERB:\n",
        "        out = aug_reverb(out, sr)\n",
        "\n",
        "    out = peak_normalize(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# [셀 6] 증강 실행:\n",
        "# =========================================\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# 한 wav를 받아서 그 wav에 대해 Augmenatation하고 y와 sr 반환\n",
        "def data_augmentation(y, sr):\n",
        "  y_aug = random_augment(y, sr)\n",
        "  return y_aug, sr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "851d59b6"
      },
      "source": [
        "This function converts audio waveforms into Mel spectrograms, which are commonly used features for audio classification tasks. It uses `librosa` to perform Short-Time Fourier Transform (STFT) and compute the Mel spectrogram on a decibel scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf5395d1"
      },
      "source": [
        "#Mel Spectrogram 변환 후 Npy변환\n",
        "\n",
        "def create_mel_spectrogram(y, sr, n_fft=2048, hop_length = 512, n_mels = 128):\n",
        "    \"\"\"\n",
        "    오디오 파형(y)과 샘플링 속도(sr)를 받아 멜 스펙트로그램을 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        y (np.ndarray): 오디오 파형 데이터 (float32).\n",
        "        sr (int): 오디오의 샘플링 속도.\n",
        "        n_fft (int): FFT 윈도우 크기.\n",
        "        hop_length (int): 홉 길이 (프레임 간의 샘플 수).\n",
        "        n_mels (int): 멜 밴드의 수.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 계산된 멜 스펙트로그램 (NumPy 배열).\n",
        "    \"\"\"\n",
        "\n",
        "    # STFT, short time fourier transform 계산, 결괏값은 복소수 Spectrum들의 합쳐진 값인 Spectrogram\n",
        "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "    # 진폭, Amplitude Spectrogram으로 변환\n",
        "    S_amplitude = np.abs(D)\n",
        "\n",
        "        # 멜 스펙트로그램으로 변환\n",
        "    # librosa.feature.melspectrogram은 파워 스펙트로그램(amplitude**2) 또는 진폭 스펙트로그램을 입력받을 수 있습니다.\n",
        "    # 여기서는 진폭 스펙트로그램을 사용합니다. power=2.0으로 설정하면 파워 스펙트로그램을 사용하게 됩니다.\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(S=S_amplitude, sr=sr, n_mels=n_mels, hop_length=hop_length, n_fft=n_fft)\n",
        "\n",
        "      # (옵션) 데시벨(dB) 스케일로 변환 (사람의 청각은 로그 스케일에 가깝기 때문에 흔히 사용됩니다)\n",
        "    # ref=np.max 는 스펙트로그램의 최대값을 기준으로 정규화합니다.\n",
        "    mel_spectrogram_db = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "    # 일반적으로 dB 스케일의 멜 스펙트로그램을 특징으로 많이 사용합니다.\n",
        "    return mel_spectrogram_db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38b84a63"
      },
      "source": [
        "This cell defines functions for encoding categorical labels (instrument names in this case) into numerical indices and one-hot encoded vectors, which are required for training classification models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dd5e91a"
      },
      "source": [
        "#One-Hot Encoder 생성 코드\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# IRMAS 고정 클래스(훈련 기준 11개)\n",
        "INST_CODES = [\"cel\",\"cla\",\"flu\",\"gac\",\"gel\",\"org\",\"pia\",\"sax\",\"tru\",\"vio\",\"voi\"]\n",
        "inst2idx = {c:i for i,c in enumerate(INST_CODES)}\n",
        "idx2inst = {i:c for c,i in inst2idx.items()}\n",
        "\n",
        "def label_to_index(code: str) -> int:\n",
        "    return inst2idx[code]  # KeyError가 싫으면 inst2idx.get(code, default)로\n",
        "\n",
        "def index_to_onehot(idx: int, num_classes=len(INST_CODES)) -> np.ndarray:\n",
        "    return np.eye(num_classes, dtype=np.float32)[idx]\n",
        "\n",
        "def code_to_onehot(code: str) -> np.ndarray:\n",
        "    return index_to_onehot(label_to_index(code))\n",
        "\n",
        "# 사용 예시\n",
        "y_idx = label_to_index(\"gac\")        # 3\n",
        "y_1h  = code_to_onehot(\"gac\")        # [0,0,0,1,0, ...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b836fe5"
      },
      "source": [
        "This cell installs SoX, a command-line utility for audio processing, which is used by the `torchaudio.sox_effects` module for some of the data augmentation techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41daba8f"
      },
      "source": [
        "# Install SoX\n",
        "!apt-get update\n",
        "!apt-get install -y sox libsox-dev libsox-fmt-all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "438e58a9"
      },
      "source": [
        "This cell is intended for downloading and processing a dataset (IRMAS in this case). It iterates through the dataset, loads audio files, applies data augmentation (using the functions defined previously), converts the augmented audio to Mel spectrograms, and saves the features and corresponding one-hot encoded labels as `.npy` files to Google Drive. It includes logic to limit the number of data points processed per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ea0126d"
      },
      "source": [
        "# DataSet 다운로드 하는 함수\n",
        "\n",
        "import mirdata\n",
        "from pathlib import Path\n",
        "\n",
        "# 증강 개수: 각 원본 파일당 생성할 증강본 수\n",
        "AUG_PER_FILE = 2\n",
        "\n",
        "META_DIR = \"/content/drive/MyDrive/audioPractice/meta\"\n",
        "\n",
        "DATA_HOME = Path(\"/content/IRMAS\")   # 저장 위치(드라이브 마운트 경로도 가능)\n",
        "\n",
        "# ds = mirdata.initialize(\"irmas\", data_home=str(DATA_HOME))\n",
        "# # 훈련만 받기: 키 이름은 mirdata에 하드코딩되어 있습니다.\n",
        "# # ['training_data','testing_data_1','testing_data_2','testing_data_3']\n",
        "# ds.download(partial_download=[\"training_data\"], force_overwrite=True)\n",
        "\n",
        "# Class 별 이용할 데이터 수(데이터셋에서)\n",
        "DATA_PER_CLASS = 100\n",
        "\n",
        "class_count = {}\n",
        "\n",
        "#각 세트에서 300개씩만 처리하자\n",
        "tracks = ds.load_tracks()\n",
        "\n",
        "#tid = 악기 id, tr = 악기 Track 객체\n",
        "for tid, tr in tracks.items():\n",
        "    if not tr.train:    # 안전장치: 훈련용만\n",
        "        continue\n",
        "    wav_path = tr.audio_path                 # .wav 절대경로\n",
        "    label_codes = tr.instrument              # ['gac']처럼 리스트\n",
        "    label = label_codes[0]                   # 훈련셋은 단일 라벨\n",
        "\n",
        "    # npy 의 Class 분류 위한 폴더 경로 생성\n",
        "    output_dir = Path(META_DIR) / label\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    #class count 추가\n",
        "    class_count[label] = class_count.get(label, 0) + 1\n",
        "\n",
        "    #이미 Class 별 데이터 수가 DATA_PER_CLASS를 넘었으면 Skip\n",
        "    if class_count[label] > DATA_PER_CLASS:\n",
        "        continue\n",
        "\n",
        "    # 이후 npy 저장을 위한 filename 추출\n",
        "    original_filename = os.path.basename(tr.audio_path)\n",
        "    base_filename = os.path.splitext(original_filename)[0] # 확장자 제거\n",
        "\n",
        "    # Label Encoidng=\n",
        "    label_oneHot = code_to_onehot(label)\n",
        "\n",
        "    #Mono로 Load하기\n",
        "    y, sr = load_mono(path=wav_path)\n",
        "\n",
        "    #원본 먼저 변환하고 저장해놓기\n",
        "    mel_spectrogram = create_mel_spectrogram(y=y, sr=sr)\n",
        "\n",
        "    #이제 저장해야지\n",
        "    features_path = os.path.join(output_dir, f\"{base_filename}_features.npy\")\n",
        "    label_path = os.path.join(output_dir, f\"{base_filename}_label.npy\")\n",
        "\n",
        "    # 데이터 저장\n",
        "    np.save(features_path, mel_spectrogram)\n",
        "    np.save(label_path, label_oneHot) # 라벨도 .npy로 저장\n",
        "\n",
        "\n",
        "\n",
        "    # Mel Spectrogram 획득\n",
        "    for i in range(1, AUG_PER_FILE + 1):\n",
        "\n",
        "        #Augmentation 진행\n",
        "        y_aug, sr_aug = data_augmentation(y, sr)\n",
        "\n",
        "        #mel Spectrogram 획득\n",
        "        mel_spectrogram = create_mel_spectrogram(y_aug, sr_aug)\n",
        "\n",
        "\n",
        "\n",
        "        #이제 저장해야지\n",
        "        features_path = os.path.join(output_dir, f\"{base_filename}_{i}_features.npy\")\n",
        "        label_path = os.path.join(output_dir, f\"{base_filename}_{i}_label.npy\")\n",
        "\n",
        "        # 데이터 저장\n",
        "        np.save(features_path, mel_spectrogram)\n",
        "        np.save(label_path, label_oneHot) # 라벨도 .npy로 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcf4f4a0"
      },
      "source": [
        "This section handles the process of copying the preprocessed `.npy` feature and label files from Google Drive to the local Colab instance's SSD. This is done to speed up data loading during model training. It uses the `rsync` command for efficient copying."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fc8925b"
      },
      "source": [
        "# Google Drive의 파일을 실제 Colab 인스턴스의 ssd로 다운받아두는 작업\n",
        "#\n",
        "\n",
        "# 실제 Google Drive에 npy들 저장되어 있는 경로\n",
        "META_DIR = \"/content/drive/MyDrive/audioPractice/meta\"\n",
        "\n",
        "# Colab 인스턴스 저장 경로\n",
        "LOCAL_DIR = \"/content/data\"\n",
        "\n",
        "# Google Drive 데이터 복사\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 로컬 저장소 디렉토리가 없으면 생성\n",
        "os.makedirs(LOCAL_DIR, exist_ok=True)\n",
        "\n",
        "# Google Drive에서 로컬로 파일 복사\n",
        "# rsync 명령어를 사용하여 복사합니다. -a: 아카이브 모드, -v: 상세 출력, --progress: 진행 상황 표시\n",
        "# --ignore-existing: 이미 로컬에 파일이 존재하면 건너뛰어 시간을 절약합니다.\n",
        "# Google Drive 경로 끝에 /를 붙이면 해당 디렉토리의 내용물을, 안 붙이면 디렉토리 자체를 복사합니다.\n",
        "# 여기서는 내용물을 복사하므로 META_DIR 뒤에 /를 붙입니다.\n",
        "print(f\"Copying data from {META_DIR} to {LOCAL_DIR}...\")\n",
        "\n",
        "# tqdm과 연동하여 진행률 표시\n",
        "# rsync의 --info=progress2 옵션은 전체 복사 크기와 현재까지 복사된 크기를 출력합니다.\n",
        "# 이를 파싱하여 tqdm으로 진행률을 업데이트합니다.\n",
        "# 주의: 이 방법은 rsync 출력이 특정 형식일 때만 작동하며, 환경에 따라 다를 수 있습니다.\n",
        "# 간단하게는 !rsync -av --progress \"{META_DIR}/\" \"{LOCAL_DIR}/\" 만 사용해도 됩니다.\n",
        "\n",
        "# rsync 명령 실행\n",
        "process = subprocess.Popen(\n",
        "    ['rsync', '-av', '--progress', f'{META_DIR}/', f'{LOCAL_DIR}/'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    universal_newlines=True\n",
        ")\n",
        "\n",
        "# 진행 상황 파싱 및 tqdm 업데이트\n",
        "# 이 부분은 rsync의 실제 출력 형식을 보고 조정해야 할 수 있습니다.\n",
        "# 간단한 복사 진행률 확인을 위해 stdout을 실시간으로 읽습니다.\n",
        "# 더 정확한 tqdm 연동은 rsync 출력을 정규식 등으로 파싱해야 합니다.\n",
        "\n",
        "# 간단한 진행 메시지만 출력합니다.\n",
        "# 정확한 tqdm 진행률은 구현이 복잡하므로, 여기서는 rsync 자체의 --progress 출력을 사용합니다.\n",
        "!rsync -av --progress \"{META_DIR}/\" \"{LOCAL_DIR}/\"\n",
        "\n",
        "print(\"Data copy complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45d14ddc"
      },
      "source": [
        "This cell prepares the data for training by creating a `tf.data.Dataset` from the local `.npy` files. It defines a function `_load_npy` to load the feature and label arrays and ensures they have the correct shape and data type. It then configures the dataset for shuffling, parallel loading, and padding batches to handle variable-length time series data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b826248c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "#DataLoader 및 Generator 만들 예정 부분 셀 코드\n",
        "\n",
        "# npy 파일이 저장된 루트 경로\n",
        "# META_DIR = \"/content/drive/MyDrive/audioPractice/meta\" # Google Drive 경로는 이제 사용하지 않습니다.\n",
        "\n",
        "# 로컬 저장소 경로를 사용합니다.\n",
        "LOCAL_DIR = \"/content/data\"\n",
        "\n",
        "\n",
        "def collect_pairs(meta_root):\n",
        "    pairs = []\n",
        "    for root, _, _ in os.walk(meta_root):\n",
        "        for f in sorted(glob.glob(os.path.join(root, \"*_features.npy\"))):\n",
        "            base = f[:-len(\"_features.npy\")]\n",
        "            lf = base + \"_label.npy\"\n",
        "            if os.path.exists(lf):\n",
        "                pairs.append((f, lf))\n",
        "            else:\n",
        "                print(f\"[WARN] label missing for {f}\")\n",
        "    return pairs\n",
        "\n",
        "# collect_pairs 함수 호출 시 LOCAL_DIR 사용\n",
        "pairs = collect_pairs(LOCAL_DIR)\n",
        "print(\"num pairs:\", len(pairs))\n",
        "\n",
        "\n",
        "\n",
        "#넌 뭐야? 각 경로 쌍 리스트 만들어두기!\n",
        "feature_paths = [p[0] for p in pairs]\n",
        "label_paths   = [p[1] for p in pairs]\n",
        "\n",
        "# 한 번에 모델로 들어갈 Batch 크기\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "\n",
        "#DataSet 구성\n",
        "ds = tf.data.Dataset.from_tensor_slices((feature_paths, label_paths))\n",
        "ds_initial = tf.data.Dataset.from_tensor_slices((feature_paths, label_paths))\n",
        "\n",
        "#npy load하는 메서드\n",
        "def _load_npy(feat_path, lab_b):\n",
        "\n",
        "\n",
        "    def py_load(feat_b, lab_b):\n",
        "\n",
        "        #실제 npy 읽기\n",
        "        fx = np.load(feat_b.decode(\"utf-8\"))        # (F, T[, C]) 형태 가정\n",
        "        y  = np.load(lab_b.decode(\"utf-8\"))         # (num_classes,) 혹은 (,) class idx\n",
        "\n",
        "        # 형/dtype 정리\n",
        "        if fx.ndim == 2:        # 채널 축 없으면 추가\n",
        "            fx = fx[..., np.newaxis]\n",
        "\n",
        "        #float 32로\n",
        "        fx = fx.astype(np.float32, copy=False)\n",
        "\n",
        "        y  = y.astype(np.float32, copy=False) if y.ndim>0 else np.int64(y)  # 원핫이면 float32, 인덱스면 int\n",
        "\n",
        "        return fx, y\n",
        "\n",
        "    x, y = tf.numpy_function(py_load, [feat_path, lab_b],\n",
        "                             [tf.float32, tf.float32])  # 인덱스 라벨이면 tf.int64로 바꿔도 됨\n",
        "\n",
        "    # 부분 shape 고정(Conv2D는 rank/일부 축 정보 필요)\n",
        "    # 시간 축은 가변이므로 None으로 둡니다.\n",
        "    x.set_shape([128, None, 1])   # (F, T, C) — F=128, C=1 고정, T 가변\n",
        "    # 라벨 shape 고정 (원핫 인코딩된 11개 클래스)\n",
        "    y.set_shape([11])\n",
        "    return x, y\n",
        "\n",
        "# (선택) 속도 우선이면 비결정성 허용\n",
        "options = tf.data.Options()\n",
        "options.deterministic = False  # 재현성이 더 중요하면 이 줄 제거\n",
        "\n",
        "\n",
        "ds = (ds\n",
        "      .shuffle(len(pairs)) # 매 epoch마다 random 순서\n",
        "      .map(_load_npy, num_parallel_calls=tf.data.AUTOTUNE) # 병렬 로딩\n",
        "      # padded_batch를 사용하여 가변 길이를 처리합니다.\n",
        "      # padded_shapes: 각 텐서의 패딩될 모양을 지정합니다. None은 해당 축이 가변적임을 나타냅니다.\n",
        "      # padding_values: 패딩에 사용할 값을 지정합니다. 0.0은 0으로 패딩합니다.\n",
        "      .padded_batch(BATCH_SIZE,\n",
        "                    padded_shapes=([128, None, 1], [11]),\n",
        "                    padding_values=(tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)),\n",
        "                    drop_remainder=False) # Batch 묵기\n",
        "      .with_options(options)\n",
        "      .prefetch(tf.data.AUTOTUNE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02969f8e"
      },
      "source": [
        "This cell performs a quick check on the loaded `.npy` files to confirm their shapes and data types, ensuring that the data loading and preprocessing steps were successful before feeding the data into a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13dc3d5a"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# pairs 리스트는 이미 이전 셀에서 생성되었다고 가정합니다.\n",
        "# 만약 pairs 리스트가 정의되지 않았다면, 이전 셀(3d184f11)을 먼저 실행해야 합니다.\n",
        "if 'pairs' not in locals():\n",
        "    print(\"Error: 'pairs' list not found. Please run the cell that collects file pairs first.\")\n",
        "else:\n",
        "    print(f\"Total number of pairs found: {len(pairs)}\")\n",
        "\n",
        "    # 처음 몇 개의 파일 형태 확인\n",
        "    print(\"\\nShape of the first 5 feature files:\")\n",
        "    for i in range(min(5, len(pairs))):\n",
        "        feature_path = pairs[i][0]\n",
        "        try:\n",
        "            features = np.load(feature_path)\n",
        "            print(f\"  {os.path.basename(feature_path)} shape: {features.shape}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"  Error loading {os.path.basename(feature_path)}: File not found.\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error loading {os.path.basename(feature_path)}: {e}\")\n",
        "\n",
        "    # 랜덤으로 몇 개의 파일 형태 확인\n",
        "    print(\"\\nShape of 5 random feature files:\")\n",
        "    random_indices = random.sample(range(len(pairs)), min(5, len(pairs)))\n",
        "    for i in random_indices:\n",
        "        feature_path = pairs[i][0]\n",
        "        try:\n",
        "            features = np.load(feature_path)\n",
        "            print(f\"  {os.path.basename(feature_path)} shape: {features.shape}\")\n",
        "        except FileNotFoundError:\n",
        "             print(f\"  Error loading {os.path.basename(feature_path)}: File not found.\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error loading {os.path.basename(feature_path)}: {e}\")\n",
        "\n",
        "    # 라벨 파일 형태도 선택적으로 확인 가능\n",
        "    # print(\"\\nShape of the first 5 label files:\")\n",
        "    # for i in range(min(5, len(pairs))):\n",
        "    #     label_path = pairs[i][1]\n",
        "    #     try:\n",
        "    #         labels = np.load(label_path)\n",
        "    #         print(f\"  {os.path.basename(label_path)} shape: {labels.shape}\")\n",
        "    #     except FileNotFoundError:\n",
        "    #          print(f\"  Error loading {os.path.basename(label_path)}: File not found.\")\n",
        "    #     except Exception as e:\n",
        "    #         print(f\"  Error loading {os.path.basename(label_path)}: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c6f4cc6"
      },
      "source": [
        "This cell verifies the functionality of the `tf.data.Dataset` pipeline configured in the previous step. It shows the output shape of the dataset elements after mapping the loading function and after batching with padding, confirming that the data is being processed as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30e497d3"
      },
      "source": [
        "## -- tf.data.Dataset 동작 확인\n",
        "\n",
        "\n",
        "print(\"--- Initial Dataset (paths) ---\")\n",
        "for feat_path, lab_path in ds_initial.take(5): # 처음 5개 요소만 확인\n",
        "    print(f\"Feature Path: {feat_path.numpy().decode('utf-8')}, Label Path: {lab_path.numpy().decode('utf-8')}\")\n",
        "\n",
        "\n",
        "ds_mapped = ds_initial.map(_load_npy, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"\\n--- Dataset after map(_load_npy) ---\")\n",
        "for features, labels in ds_mapped.take(3): # 처음 3개 요소만 확인\n",
        "    print(f\"Features shape: {features.shape}, Labels shape: {labels.shape}\")\n",
        "    # 필요하다면 실제 데이터 값의 일부를 출력해볼 수도 있습니다.\n",
        "    # print(\"Features example:\", features.numpy().flatten()[:10])\n",
        "    # print(\"Labels example:\", labels.numpy())\n",
        "\n",
        "\n",
        "ds_batched = ds_mapped.padded_batch(\n",
        "    BATCH_SIZE,\n",
        "    padded_shapes=([128, None, 1], [11]),\n",
        "    padding_values=(tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)),\n",
        "    drop_remainder=False\n",
        ")\n",
        "\n",
        "print(\"\\n--- Dataset after padded_batch ---\")\n",
        "for batch_features, batch_labels in ds_batched.take(2): # 처음 2개 배치만 확인\n",
        "    print(f\"Batch Features shape: {batch_features.shape}, Batch Labels shape: {batch_labels.shape}\")\n",
        "    # 배치 내의 데이터 값과 패딩 상태를 확인해볼 수 있습니다.\n",
        "    # print(\"Batch Features example (first element, first few values):\", batch_features.numpy()[0, :10, 0, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aca40eeb"
      },
      "source": [
        "This cell is a redundant check to ensure that the `pairs` list, containing the paths to the feature and label files, is correctly loaded and that the shapes and data types of randomly selected `.npy` files are as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7d1d675"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# pairs 리스트에서 임의의 features 및 label 파일 경로 선택\n",
        "# pairs는 이전에 collect_pairs 함수를 통해 생성되었습니다.\n",
        "if len(pairs) > 0:\n",
        "    random_pair = random.choice(pairs)\n",
        "    feature_path = random_pair[0]\n",
        "    label_path = random_pair[1]\n",
        "\n",
        "    print(f\"Selected Feature File: {feature_path}\")\n",
        "    print(f\"Selected Label File: {label_path}\")\n",
        "\n",
        "    try:\n",
        "        # .npy 파일 로드\n",
        "        features = np.load(feature_path)\n",
        "        labels = np.load(label_path)\n",
        "\n",
        "        # shape 출력\n",
        "        print(f\"Features shape: {features.shape}\")\n",
        "        print(f\"Labels shape: {labels.shape}\")\n",
        "\n",
        "        # 데이터 타입 출력 (참고용)\n",
        "        print(f\"Features dtype: {features.dtype}\")\n",
        "        print(f\"Labels dtype: {labels.dtype}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: One or both selected files not found. Please ensure the paths are correct and the files exist.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"No pairs found in the list. Please ensure the data processing step completed successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63d3c16b"
      },
      "source": [
        "This section defines the architecture of a Convolutional Neural Network (CNN) model for audio classification using TensorFlow/Keras. The model consists of convolutional layers for spatial feature extraction, followed by pooling, batch normalization, activation functions, dropout for regularization, and a final dense layer with softmax activation for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48a7b870"
      },
      "source": [
        "# CNN Model 구조 정의해보기\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "\n",
        "#IRMAS 기본 Class 수는 11개\n",
        "num_classes = 11\n",
        "\n",
        "# 다음과 같은 구조로 저장되어 있으나, Feature은 DataLoader에 의해 3차원 변환됨(Channel = 1)\n",
        "# Features shape: (128, 130)\n",
        "# Labels shape: (11,)\n",
        "# Features dtype: float32\n",
        "# Labels dtype: float32\n",
        "\n",
        "# 함수형으로 구현한 Model 사용해보기\n",
        "def build_cnn(input_shape = (128, None, 1), num_classes= num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(32, (3,3), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(64, (3,3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(128, (3,3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    # Head\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)   # 파라미터 적고 과적합 덜함\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = build_cnn()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4626d3a"
      },
      "source": [
        "This cell is a placeholder for the code to start the training process. The actual training loop is implemented in the subsequent K-Fold cross-validation cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "493bfdc2"
      },
      "source": [
        "# 학습 시작 코드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d29083b"
      },
      "source": [
        "This section implements K-Fold cross-validation to train and evaluate the defined CNN model. It splits the data into `n_splits` folds, trains a new model on the training folds, evaluates it on the validation fold, and records the loss and accuracy for each fold. It also includes Early Stopping to prevent overfitting and plots the training history for the first fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31539672"
      },
      "source": [
        "# K-Fold 교차 검증 설정 및 학습/평가 코드\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "import os\n",
        "\n",
        "# K-Fold 설정\n",
        "n_splits = 5  # 5-Fold 교차 검증\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42) # 데이터 순서를 섞고, 재현성을 위해 random_state 설정\n",
        "\n",
        "# 데이터셋 로딩 및 전처리 함수 (이전에 정의된 _load_npy 함수와 padded_batch 사용)\n",
        "# 여기서는 기존의 ds 구성 방식을 K-Fold 분할에 맞춰 수정합니다.\n",
        "\n",
        "# K-Fold 결과를 저장할 리스트\n",
        "fold_results = []\n",
        "fold_histories = []\n",
        "\n",
        "# 전체 데이터셋 (pairs)에서 feature_paths와 label_paths 분리\n",
        "all_feature_paths = np.array([p[0] for p in pairs])\n",
        "all_label_paths = np.array([p[1] for p in pairs])\n",
        "\n",
        "# K-Fold 분할 시작\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(all_feature_paths)):\n",
        "    print(f\"\\n--- Starting Fold {fold+1}/{n_splits} ---\")\n",
        "\n",
        "    # 현재 폴드의 훈련 및 검증 데이터 경로\n",
        "    train_feature_paths = all_feature_paths[train_index]\n",
        "    train_label_paths = all_label_paths[train_index]\n",
        "\n",
        "    val_feature_paths = all_feature_paths[val_index]\n",
        "    val_label_paths = all_label_paths[val_index]\n",
        "\n",
        "    # 훈련 및 검증 데이터셋 생성\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((train_feature_paths, train_label_paths))\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((val_feature_paths, val_label_paths))\n",
        "\n",
        "    # 기존 _load_npy 함수를 사용하여 데이터 로드 및 전처리 적용\n",
        "    train_ds = (train_ds\n",
        "                .shuffle(len(train_feature_paths)) # 훈련 데이터만 섞음\n",
        "                .map(_load_npy, num_parallel_calls=tf.data.AUTOTUNE) # 병렬 로딩\n",
        "                .padded_batch(BATCH_SIZE,\n",
        "                              padded_shapes=([128, None, 1], [11]),\n",
        "                              padding_values=(tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)),\n",
        "                              drop_remainder=False) # Batch 묵기\n",
        "                .with_options(options)\n",
        "                .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "    val_ds = (val_ds\n",
        "              .map(_load_npy, num_parallel_calls=tf.data.AUTOTUNE) # 병렬 로딩\n",
        "              .padded_batch(BATCH_SIZE,\n",
        "                            padded_shapes=([128, None, 1], [11]),\n",
        "                            padding_values=(tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)),\n",
        "                            drop_remainder=False) # Batch 묵기\n",
        "              .with_options(options)\n",
        "              .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "\n",
        "    # 새로운 모델 인스턴스 생성 (각 폴드마다 초기화된 모델 사용)\n",
        "    # build_cnn 함수는 이전에 정의된 셀 (vK1fb-FsZwI3)에 있습니다.\n",
        "    # input_shape은 데이터의 형태에 맞춰 ([128, None, 1])로 지정해야 합니다.\n",
        "    model = build_cnn(input_shape=(128, None, 1))\n",
        "\n",
        "\n",
        "    # 모델 컴파일\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), # 예시 학습률\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # 콜백 설정 (Early Stopping)\n",
        "    # patience: 개선이 없을 때 몇 epoch을 더 기다릴지\n",
        "    # restore_best_weights: 학습 중 가장 성능이 좋았던 가중치를 복원할지 여부\n",
        "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "    # 모델 학습\n",
        "    # steps_per_epoch와 validation_steps를 설정하면 더 정확한 진행률 확인 가능\n",
        "    # train_steps = tf.data.experimental.cardinality(train_ds).numpy() # 데이터셋 크기를 알아내는 방법 중 하나\n",
        "    # val_steps = tf.data.experimental.cardinality(val_ds).numpy()\n",
        "    history = model.fit(train_ds,\n",
        "                        # steps_per_epoch=train_steps,\n",
        "                        epochs=50, # 충분히 큰 에포크 수를 설정하고 Early Stopping 활용\n",
        "                        validation_data=val_ds,\n",
        "                        # validation_steps=val_steps,\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=1) # 학습 진행 상황 출력\n",
        "\n",
        "    # 폴드 결과 평가\n",
        "    print(f\"\\n--- Evaluating Fold {fold+1}/{n_splits} ---\")\n",
        "    loss, accuracy = model.evaluate(val_ds, verbose=0)\n",
        "    print(f\"Fold {fold+1} - Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    fold_results.append({'loss': loss, 'accuracy': accuracy})\n",
        "    fold_histories.append(history.history)\n",
        "\n",
        "# K-Fold 교차 검증 결과 요약\n",
        "print(\"\\n--- K-Fold Cross-Validation Results ---\")\n",
        "avg_loss = np.mean([res['loss'] for res in fold_results])\n",
        "avg_accuracy = np.mean([res['accuracy'] for res in fold_results])\n",
        "\n",
        "print(f\"Average Validation Loss: {avg_loss:.4f}\")\n",
        "print(f\"Average Validation Accuracy: {avg_accuracy:.4f}\")\n",
        "\n",
        "# 각 폴드별 상세 결과 출력 (선택 사항)\n",
        "# for i, res in enumerate(fold_results):\n",
        "#     print(f\"  Fold {i+1}: Loss={res['loss']:.4f}, Accuracy={res['accuracy']:.4f}\")\n",
        "\n",
        "# 가장 좋은 성능을 보인 폴드의 모델을 사용하거나, 전체 데이터로 재학습 등 후속 작업 진행 가능\n",
        "\n",
        "# 평가 결과 시각화 (선택 사항)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 각 폴드의 학습 history에서 손실 및 정확도 가져오기\n",
        "# 주의: Early Stopping으로 인해 각 폴드의 epoch 수가 다를 수 있습니다.\n",
        "# 여기서는 각 폴드의 최종 성능만 확인하거나, history를 개별적으로 시각화할 수 있습니다.\n",
        "\n",
        "# 예시: 각 폴드의 학습 및 검증 손실 그래프 그리기\n",
        "# 모든 폴드의 history를 한 그래프에 그리면 복잡할 수 있습니다.\n",
        "# 여기서는 예시로 첫 번째 폴드의 history를 그립니다.\n",
        "\n",
        "if fold_histories:\n",
        "    first_fold_history = fold_histories[0]\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 손실 그래프\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(first_fold_history['loss'], label='Train Loss')\n",
        "    plt.plot(first_fold_history['val_loss'], label='Val Loss')\n",
        "    plt.title('Loss vs. Epochs (First Fold)')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # 정확도 그래프\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(first_fold_history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(first_fold_history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title('Accuracy vs. Epochs (First Fold)')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59dbae47"
      },
      "source": [
        "This section defines the architecture of a Convolutional Recurrent Neural Network (CRNN) model, which combines CNN layers for spatial feature extraction and Bidirectional LSTM layers for temporal sequence modeling. This type of model is often effective for audio classification tasks involving time-varying features. It includes layers for convolution, pooling, batch normalization, dropout, permutation and TimeDistributed Flatten to prepare data for the RNN, and a final dense layer for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d48b8cf"
      },
      "source": [
        "#Sequential 관련 모델들 시험해보기\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "\n",
        "# IRMAS 기본 Class 수는 11개\n",
        "num_classes = 11\n",
        "\n",
        "# 기존 DataLoader에서 생성되는 데이터 형태: (128, None, 1) -> 배치 후 (BATCH_SIZE, 128, Max_Time, 1)\n",
        "input_shape = (128, None, 1) # Mel Spectrogram (n_mels, time_steps, channels)\n",
        "\n",
        "def build_crnn(input_shape=input_shape, num_classes=num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # --- CNN 부분 ---\n",
        "    # Mel Spectrogram에서 공간적 특징 추출\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x) # 주파수 축과 시간 축 모두 압축\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x) # 주파수 축과 시간 축 모두 압축\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    # 마지막 MaxPooling은 시간 축만 압축하거나, Global Pooling을 고려할 수 있습니다.\n",
        "    # 여기서는 시간 축 압축을 위해 (1, 2) 또는 (1, 4) 등을 사용해 봅시다.\n",
        "    # 주파수 축은 RNN 입력으로 넘어가기 전에 납작하게 만들 것이므로, 여기서 너무 압축하지 않는 것이 좋습니다.\n",
        "    # 따라서 마지막 MaxPooling은 시간 축에 더 집중하거나 (1, P) 또는 사용하지 않을 수 있습니다.\n",
        "    # 일반적인 오디오 CRNN에서는 CNN 후 특징 맵을 시간 축 방향으로 펼칩니다.\n",
        "    # 시간 축 압축을 위해 (1, 2)를 사용해 보겠습니다.\n",
        "    x = layers.MaxPooling2D((1, 2))(x) # 시간 축만 2배 압축\n",
        "\n",
        "    # --- 특징 맵을 RNN 입력 형태로 변환 ---\n",
        "    # CNN 출력 형태: (Batch, F', T', C')\n",
        "    # RNN 입력 형태: (Batch, T', F'*C')\n",
        "    # tf.keras.layers.Permute 또는 Reshape, TimeDistributed 등을 사용할 수 있습니다.\n",
        "    # 가변 길이 시간 축 처리를 위해 Reshape보다는 TimeDistributed를 사용하는 것이 더 유연할 수 있으나,\n",
        "    # 여기서는 GlobalAveragePooling2D와 유사하게 공간 축(주파수)을 납작하게 만들고 시간 축을 시퀀스로 사용합니다.\n",
        "\n",
        "    # CNN 출력 shape 확인: (Batch, F', T', C') -> 예를 들어 (None, 16, None, 128) after max pooling (1,2)\n",
        "    # 주파수 축 (F')을 특징 벡터로 사용하고, 시간 축 (T')을 시퀀스 길이로 사용합니다.\n",
        "    # Reshape을 사용하여 (Batch, T', F' * C') 형태로 만듭니다.\n",
        "    # 가변 시간 축 때문에 Reshape이 바로 작동하지 않을 수 있습니다.\n",
        "    # 대신, TimeDistributed(Flatten) 또는 Lambda 레이어를 사용하여 각 타임스텝의 특징을 납작하게 만듭니다.\n",
        "    # 여기서는 Lambda를 사용하여 (Batch, T', F' * C') 형태로 변환합니다.\n",
        "    # Lambda 레이어는 사용자 정의 함수를 레이어로 추가할 수 있게 해줍니다.\n",
        "    # 람다 함수는 입력 텐서 x를 받아서 원하는 변환을 수행합니다.\n",
        "    # x.shape: (None, F', T', C')\n",
        "    # 목표 shape: (None, T', F' * C')\n",
        "    # 축 순서를 변경하고 Flatten을 적용합니다.\n",
        "    # Permute를 먼저 사용해 (Batch, T', F', C') 로 만든 후 Reshape 또는 Flatten\n",
        "    # TimeDistributed(Flatten())을 사용하면 각 타임스텝에 대해 Flatten을 적용합니다.\n",
        "    # (Batch, T', F', C') -> TimeDistributed(Flatten) -> (Batch, T', F'*C')\n",
        "\n",
        "    # CNN 출력 shape: (Batch, F', T', C')\n",
        "    # F' = 128 / (2*2) = 32 (MaxPooling2D (2,2) 두 번)\n",
        "    # T' = None / (2*2*2) = None / 8 (MaxPooling2D (2,2) 두 번, (1,2) 한 번)\n",
        "    # C' = 128\n",
        "    # CNN 출력 shape 예시: (None, 32, None, 128)\n",
        "\n",
        "    # TimeDistributed Flatten을 사용하기 위해 축 순서를 변경\n",
        "    # (Batch, F', T', C') -> (Batch, T', F', C')\n",
        "    x = layers.Permute((2, 1, 3))(x) # (Batch, T', F', C')\n",
        "\n",
        "    # 각 타임스텝에 대해 Flatten 적용\n",
        "    # (Batch, T', F', C') -> (Batch, T', F'*C')\n",
        "    # TimeDistributed 레이어는 입력의 첫 번째 차원(배치 차원 다음)을 시퀀스 차원으로 간주하고\n",
        "    # 그 이후 레이어를 각 시퀀스 스텝에 독립적으로 적용합니다.\n",
        "    x = layers.TimeDistributed(layers.Flatten())(x) # (Batch, T', features_per_timestep)\n",
        "    # features_per_timestep = F' * C' = 32 * 128 = 4096\n",
        "\n",
        "    # --- RNN 부분 ---\n",
        "    # 시간적 순서 모델링\n",
        "    # Bidirectional LSTM을 사용하여 양방향 문맥 학습\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x) # return_sequences=True는 다음 LSTM/GRU 레이어로 연결할 때 필요\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(128))(x) # 마지막 LSTM은 시퀀스 전체를 요약 (return_sequences=False)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # --- Head (분류) ---\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# CRNN 모델 생성 및 요약 출력\n",
        "crnn_model = build_crnn()\n",
        "crnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d50b0b32"
      },
      "source": [
        "This cell implements K-Fold cross-validation to train and evaluate the defined CRNN model. Similar to the CNN evaluation cell, it splits the data, trains the CRNN model on each fold, evaluates its performance, and summarizes the results. It also includes Early Stopping and plots the training history for the first fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41e81785"
      },
      "source": [
        "# CRNN 모델 K-Fold 교차 검증 설정 및 학습/평가 코드\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "import os\n",
        "\n",
        "# K-Fold 설정\n",
        "n_splits = 5  # 5-Fold 교차 검증\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42) # 데이터 순서를 섞고, 재현성을 위해 random_state 설정\n",
        "\n",
        "# 데이터셋 로딩 및 전처리 함수 (_load_npy 함수와 padded_batch는 이전 셀에 정의되어 있다고 가정)\n",
        "# 여기서는 기존의 ds 구성 방식을 K-Fold 분할에 맞춰 수정합니다.\n",
        "\n",
        "# K-Fold 결과를 저장할 리스트\n",
        "crnn_fold_results = []\n",
        "crnn_fold_histories = []\n",
        "\n",
        "# 전체 데이터셋 (pairs)에서 feature_paths와 label_paths 분리\n",
        "# pairs 리스트는 이전 셀 (3d184f11)에서 로컬 경로를 사용하여 이미 생성되었다고 가정합니다.\n",
        "if 'pairs' not in locals():\n",
        "    print(\"Error: 'pairs' list not found. Please run the cell that collects file pairs using LOCAL_DIR first.\")\n",
        "else:\n",
        "    all_feature_paths = np.array([p[0] for p in pairs])\n",
        "    all_label_paths = np.array([p[1] for p in pairs])\n",
        "\n",
        "    # K-Fold 분할 시작\n",
        "    for fold, (train_index, val_index) in enumerate(kf.split(all_feature_paths)):\n",
        "        print(f\"\\n--- Starting CRNN Fold {fold+1}/{n_splits} ---\")\n",
        "\n",
        "        # 현재 폴드의 훈련 및 검증 데이터 경로\n",
        "        train_feature_paths = all_feature_paths[train_index]\n",
        "        train_label_paths = all_label_paths[train_index]\n",
        "\n",
        "        val_feature_paths = all_feature_paths[val_index]\n",
        "        val_label_paths = all_label_paths[val_index]\n",
        "\n",
        "        # 훈련 및 검증 데이터셋 생성 (로컬 경로 사용)\n",
        "        train_ds = tf.data.Dataset.from_tensor_slices((train_feature_paths, train_label_paths))\n",
        "        val_ds = tf.data.Dataset.from_tensor_slices((val_feature_paths, val_label_paths))\n",
        "\n",
        "        # 기존 _load_npy 함수를 사용하여 데이터 로드 및 전처리 적용\n",
        "        # _load_npy 함수는 이전 셀 (3d184f11)에 정의되어 있습니다.\n",
        "        train_ds = (train_ds\n",
        "                    .shuffle(len(train_feature_paths)) # 훈련 데이터만 섞음\n",
        "                    .map(_load_npy, num_parallel_calls=tf.data.AUTOTUNE) # 병렬 로딩\n",
        "                    .padded_batch(BATCH_SIZE, # BATCH_SIZE는 이전 셀 (3d184f11)에 정의\n",
        "                                  padded_shapes=([128, None, 1], [11]), # padded_shapes는 이전 셀 (3d184f11)에 정의\n",
        "                                  padding_values=(tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)),\n",
        "                                  drop_remainder=False) # Batch 묵기\n",
        "                    .with_options(options) # options는 이전 셀 (3d184f11)에 정의\n",
        "                    .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "        val_ds = (val_ds\n",
        "                  .map(_load_npy, num_parallel_calls=tf.data.AUTOTUNE) # 병렬 로딩\n",
        "                  .padded_batch(BATCH_SIZE,\n",
        "                                padded_shapes=([128, None, 1], [11]),\n",
        "                                padding_values=(tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)),\n",
        "                                drop_remainder=False) # Batch 묵기\n",
        "                  .with_options(options)\n",
        "                  .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "\n",
        "        # 새로운 CRNN 모델 인스턴스 생성 (각 폴드마다 초기화된 모델 사용)\n",
        "        # build_crnn 함수는 이전 셀 (4d4e6a28)에 정의되어 있습니다.\n",
        "        # input_shape은 데이터의 형태에 맞춰 ([128, None, 1])로 지정해야 합니다.\n",
        "        crnn_model = build_crnn(input_shape=(128, None, 1))\n",
        "\n",
        "\n",
        "        # 모델 컴파일\n",
        "        crnn_model.compile(optimizer=optimizers.Adam(learning_rate=0.001), # 예시 학습률\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        # 콜백 설정 (Early Stopping)\n",
        "        # patience: 개선이 없을 때 몇 epoch을 더 기다릴지\n",
        "        # restore_best_weights: 학습 중 가장 성능이 좋았던 가중치를 복원할지 여부\n",
        "        early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "        # 모델 학습\n",
        "        history = crnn_model.fit(train_ds,\n",
        "                            epochs=50, # 충분히 큰 에포크 수를 설정하고 Early Stopping 활용\n",
        "                            validation_data=val_ds,\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=1) # 학습 진행 상황 출력\n",
        "\n",
        "        # 폴드 결과 평가\n",
        "        print(f\"\\n--- Evaluating CRNN Fold {fold+1}/{n_splits} ---\")\n",
        "        loss, accuracy = crnn_model.evaluate(val_ds, verbose=0)\n",
        "        print(f\"CRNN Fold {fold+1} - Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        crnn_fold_results.append({'loss': loss, 'accuracy': accuracy})\n",
        "        crnn_fold_histories.append(history.history)\n",
        "\n",
        "    # K-Fold 교차 검증 결과 요약\n",
        "    print(\"\\n--- CRNN K-Fold Cross-Validation Results ---\")\n",
        "    avg_loss = np.mean([res['loss'] for res in crnn_fold_results])\n",
        "    avg_accuracy = np.mean([res['accuracy'] for res in crnn_fold_results])\n",
        "\n",
        "    print(f\"CRNN Average Validation Loss: {avg_loss:.4f}\")\n",
        "    print(f\"CRNN Average Validation Accuracy: {avg_accuracy:.4f}\")\n",
        "\n",
        "    # 각 폴드별 상세 결과 출력 (선택 사항)\n",
        "    # for i, res in enumerate(crnn_fold_results):\n",
        "    #     print(f\"  CRNN Fold {i+1}: Loss={res['loss']:.4f}, Accuracy={res['accuracy']:.4f}\")\n",
        "\n",
        "    # 평가 결과 시각화 (선택 사항)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    if crnn_fold_histories:\n",
        "        # 모든 폴드의 history를 한 그래프에 그리면 복잡할 수 있습니다.\n",
        "        # 여기서는 예시로 첫 번째 폴드의 history를 그립니다.\n",
        "        first_fold_history = crnn_fold_histories[0]\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # 손실 그래프\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(first_fold_history['loss'], label='Train Loss')\n",
        "        plt.plot(first_fold_history['val_loss'], label='Val Loss')\n",
        "        plt.title('CRNN Loss vs. Epochs (First Fold)')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # 정확도 그래프\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(first_fold_history['accuracy'], label='Train Accuracy')\n",
        "        plt.plot(first_fold_history['val_accuracy'], label='Val Accuracy')\n",
        "        plt.title('CRNN Accuracy vs. Epochs (First Fold)')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b99aae0"
      },
      "source": [
        "This is a placeholder cell indicating that the next steps might involve experimenting with Transformer models for audio classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2acc4ab"
      },
      "source": [
        "# 이 다음은 Transformer 모델 시험..."
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwTCqtSXncegexQ9t3lVwY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}